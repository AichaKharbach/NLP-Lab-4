{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:black;\">Lab3 </h2>\n",
    "\n",
    "<hr style=\"border:2px solid black;\">\n",
    "\n",
    "<h4 style=\"color:black;\">Realised by:</h4>\n",
    "<ul>\n",
    "    <li><strong style=\"color:black;\">Aicha Kharbach</strong></li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:black;\">Guided by:</h4> \n",
    "<ul>\n",
    "    <li><strong style=\"color:black;\">Pr . ELAACHAk LOTFI</strong></li>\n",
    "</ul>\n",
    "<p><strong>Objective : The main purpose behind this lab is to get familiar with NLP language models using Pytorch library.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Classification Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKRVnLUYRV0X",
    "outputId": "92765f1d-3313-487b-cf1d-e9332178d745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 (Score: 6):\n",
      "حظيت أجهزة الكمبيوتر الشخصي بعملية تطوير شاملة تعتمد على الذكاء الاصطناعي مما يعزز الآمال في أن تساعد هذه التكنولوجيا الصاعدة بقوة في إحياء صناعة شهدت تراجعا مستمرا خلال السنوات القليلة الماضية. ماذا يعني \"الكمبيوتر الشخصي المزود بالذكاء الاصطناعي\"؟ - يقول مصنعون إن هذه الأجهزة تعالج البيانات بسرعة أكبر من أجهزة الكمبيوتر التقليدية ويمكنها التعامل مع حجم أكبر من مهام الذكاء الاصطناعي مباشرة على الجهاز، بما في ذلك برامج الدردشة الآلية. - يعني هذا عدم الحاجة إلى الاعتماد على مراكز البيانات السحابية التي تُشغّل حاليا معظم تطبيقات الذكاء الاصطناعي، ومنها روبوت الدردشة الذائع الصيت (تشات جي.بي.تي) الذي طورته شركة أوبن إيه.آي. - يمكن لبعض التطبيقات أن تدعم تدريب نماذج الذكاء الاصطناعي، وهي مهمة تتطلب قوة حاسوبية كبيرة ويجري تنفيذها عادة على خوادم. - يأمل صانعو أجهزة الكمبيوتر أن تساعد تلك الخصائص في جذب المشترين مع زيادة الاعتماد على الذكاء الاصطناعي التوليدي في كل شيء بدءا من كتابة رسائل البريد الإلكتروني إلى التخطيط للإجازات. - تشير تقديرات شركة الأبحاث كاناليس إلى أن شحنات أجهزة الكمبيوتر الشخصية التي تعمل بالذكاء الاصطناعي ستتجاوز 100 مليون في عام 2025، وهو ما يشكل 40 بالمئة من إجمالي أجهزة الكمبيوتر المباعة. ما هي التكنولوجيا المستخدمة في أجهزة الكمبيوتر المزودة بالذكاء الاصطناعي؟ • تأتي أجهزة الكمبيوتر الشخصية المزودة بالذكاء الاصطناعي بمعالجات متخصصة تسمى وحدات المعالجة العصبية، والتي تتعامل مع غالبية العمليات المتعلقة بالذكاء الاصطناعي على الجهاز. • تعمل وحدات المعالجة العصبية في تناغم مع وحدات المعالجة المركزية ومعالجات الرسوم لإدارة المهام المعقدة وتحسين سرعة معالجة البيانات وتشغيل تطبيقات مثل المساعد الافتراضي الذي يعمل بالذكاء الاصطناعي. ما هي الأنواع المتوفرة من أجهزة الكمبيوتر المزودة بالذكاء الاصطناعي؟ - أطلقت مايكروسوفت الإثنين أجهزة (كوبايلوت +) التي ستبيعها هي وشركات مصنعة منها ديل وإتش.بي وسامسونغ ولينوفو وإيسر وأسوس. - الجيل الجديد أجهزة الكمبيوتر اللوحي (سيرفيس برو) والمحمول (سيرفيس لابتوب) التي أطلقتها مايكروسوفت من بين أجهزة (كوبايلوت +) الأقل سعرا، إذ تبدأ من 999 دولارا للجهاز. - الجيل السادس من جهاز (لينوفو ثينك باد تي-14) الذي من المتوقع أن تبدأ أسعاره من 1699 دولارا هو الخيار الأغلى من بين الأسعار التي أعلنتها بعض الشركات المصنعة. هل هناك أي مخاوف؟ • أثارت خاصية رئيسية جديدة من مايكروسوفت تسمى (ريكول) أو \"الاستدعاء\" بعض المخاوف المتعلقة بالخصوصية. • تتيح الخاصية تلك في برامج المساعد الافتراضي على أجهزة (كوبايلوت +) إمكانية البحث عن المعلومات واستردادها عن أي نشاط سابق على الكمبيوتر. • تعمل تلك الخاصية على تتبع كل نشاط على الكمبيوتر المحمول بدءا من المحادثات الصوتية وحتى تصفح الإنترنت، وإنشاء سجل مفصل مخزن على الجهاز. • يمكن للمستخدم بعد ذلك البحث في هذا السجل والاطلاع على الأنشطة السابقة. • عبّر بعض مستخدمي وسائل التواصل الاجتماعي عن مخاوفهم من أن الميزة قد تساعد على التجسس، في حين شبهها الملياردير إيلون ماسك بمسلسل \"بلاك ميرور\" من إنتاج نتفليكس الذي يستعرض الآثار الضارة للتكنولوجيا المتقدمة. • بحسب رايان أوليري المحلل في شركة إنترناشونال داتا فإن مصدر القلق الرئيسي تجاه تلك الخاصية هو ما إذا كانت البيانات مخزنة على الجهاز أم مركزيا، مشيرا إلى \"مخاطر كبيرة على الخصوصية\" إذا قامت مايكروسوفت بتخزين البيانات. • من ناحية أخرى يقول خبراء إن إدارة المزيد من المهام المتعلقة بالذكاء الاصطناعي مباشرة على الجهاز توفر خصوصية أكبر. • أظهرت أبحاث أجرتها شركة فورستر أن أجهزة الكمبيوتر التي تعمل بالذكاء الاصطناعي يمكن أن تساعد في تجنب استخدام البيانات الشخصية لتدريب أنظمة الذكاء الاصطناعي، فضلا عن تفادي انتهاكات حقوق الطبع والنشر وبراءات الاختراع، مما يجعلها أفضل للاستخدام المؤسسي.  \n",
      "\n",
      "Text 2 (Score: 7.5):\n",
      "أطلقت مايكروسوفت فئة جديدة من أجهزة الكمبيوتر الشخصي المزودة بميزات الذكاء الاصطناعي في الوقت الذي تسارع فيه إلى دمج تلك التكنولوجيا الناشئة في منتجات عبر أعمالها والتنافس مع أبل وألفابت. وفي مؤتمر بمقر الشركة في ريدموند بواشنطن، قدم الرئيس التنفيذي ساتيا ناديلا ما أسمته مايكروسوفت أجهزة الكمبيوتر الشخصي \"كوبايلوت+\"، قائلا إنها ستبيعها هي ومجموعة من الشركات المصنعة، ومنها إيسر وأسوس تيك كمبيوتر. وأطلقت مايكروسوفت الأجهزة الجديدة مع تداول أسهمها بالقرب من مستويات قياسية بعد ارتفاع وول ستريت مدفوعة بتوقعات بأن الذكاء الاصطناعي سيعزز أرباح الشركة ومنافساتها من شركات التكنولوجيا الكبرى. ويمكن لهذه الأجهزة التعامل مع المزيد من مهام الذكاء الاصطناعي دون الحاجة إلى مراكز البيانات السحابية، وسيبدأ سعرها من 1000 دولار وشحنها في 18 يونيو حزيران. * ميزة بحث فائقة عرضت مايكروسوفت ميزة تسمى \"ريكول\"، والتي ستساعد المستخدمين في العثور على الملفات والبيانات الأخرى التي شاهدوها على أجهزة الكمبيوتر الخاصة بهم، حتى لو كانت علامة تبويب مفتوحة في متصفح للإنترنت. وكشفت الشركة أيضا أن مساعدها الصوتي (كوبايلوت) يعمل مدربا افتراضيا في الوقت الفعلي لمستخدم يمارس لعبة الفيديو (ماينكرافت). وقال يوسف مهدي، الذي يرأس التسويق الاستهلاكي لشركة مايكروسوفت، إن الشركة تتوقع شراء 50 مليون جهاز كمبيوتر شخصي يعمل بالذكاء الاصطناعي خلال العام المقبل. وتفيد بيانات لشركة الأبحاث جارتنر بأن شحنات أجهزة الكمبيوتر الشخصية العالمية انخفضت بنحو 15 بالمئة إلى 242 مليون جهاز في العام الماضي، مما يشير إلى أن مايكروسوفت تتوقع أن تمثل الفئة الجديدة من أجهزة الكمبيوتر نحو خمس إجمالي أجهزة الكمبيوتر المباعة. وقال المسؤولون التنفيذيون في مايكروسوفت أيضا إن (تشات جي.بي.تي-4o)، أحدث نسخ روبوت الدردشة الذائع الصيت (تشات جي.بي.تي) الذي طورته شركة أوبن إيه.آي ستكون متاحة \"قريبا\" كجزء من (مايكروسوفت كوبايلوت)، برنامج الدردشة الآلي التابع للشركة. * أجهزة لوحية ومحمولة طرحت مايكروسوفت أيضا جيلا جديدا من أجهزة الكمبيوتر اللوحي(سيرفيس برو) والمحمول (سيرفيس لابتوب) التي تتميز بشرائح كوالكوم. وكشفت مايكروسوفت عن هذه التقنيات الجديدة قبل يوم واحد من بدء مؤتمرها السنوي للمطورين. وكانت أوبن إيه.آي، المدعومة من مايكروسوفت، هي وجوجل التابعة لألفابت قد عرضتا الأسبوع الماضي تقنيات ذكاء اصطناعي متنافسة يمكنها الاستجابة عبر الصوت في الوقت الفعلي ويمكن مقاطعتها، وكلاهما من السمات المميزة للمحادثات الصوتية الواقعية التي استعصت على خدمة المساعد الصوتي التي تعمل بالذكاء الاصطناعي. وأعلنت جوجل أيضا أنها ستطرح العديد من ميزات الذكاء الاصطناعي التوليدي على محرك البحث المربح الخاص بها. وتعرضت صناعة أجهزة الكمبيوتر لضغوط متزايدة من أبل منذ أن أطلقت الشركة شرائحها المستندة إلى تصميمات من شركة (آرم) وتخلصت من معالجات إنتل. ومنحت المعالجات التي صممتها أبل لأجهزة الكمبيوتر الشخصية (ماك) عمرا فائقا للبطارية وأداء أسرع من شرائح المنافسين التي تستخدم المزيد من الطاقة.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "urls = [\n",
    "    'https://www.akhbarona.com/technology/386522.html',\n",
    "    'https://www.akhbarona.com/technology/386469.html'\n",
    "]\n",
    "\n",
    "def scrape_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    text = ' '.join([p.get_text(strip=True) for p in paragraphs])\n",
    "    return text\n",
    "\n",
    "texts = [scrape_url(url) for url in urls]\n",
    "\n",
    "scored_texts = [(texts[0], 6), (texts[1], 7.5)]\n",
    "\n",
    "for i, (text, score) in enumerate(scored_texts):\n",
    "    print(f'Text {i+1} (Score: {score}):\\n{text}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umoUP2TXRsoC",
    "outputId": "c02f8213-1737-4fe7-8310-4c435de09527"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Text 1:\n",
      "حظ اجهز كمبيوتر شخص عمل تطوير شامل تعتمد ذكاء اصطناع يعزز امال تساعد تكنولوج صاعد بقو احياء صناع شهد تراجع مستمر خلال سنو قليل ماض يعن كمبيوتر شخص مزود ذكاء اصطناع يقول مصنع اجهز تعالج بيان سرع اكبر اجهز كمبيوتر تقليد ويم تعامل حجم اكبر مهام ذكاء اصطناع مباشر رامج دردش الال يعن عدم حاج اعتماد مراكز بيان سحاب حال معظم تطبيق ذكاء ومن روبو دردش ذايع الص تشا طور شرك اوب يمك لبعض تطبيق تدعم تدريب نماذج ذكاء وه مهم تتطلب قو حاسوب كبير يجر تنفيذ عاد خوادم يامل صانع اجهز كمبيوتر تساعد خصايص جذب مشتر زياد اعتماد ذكاء اصطناع توليد شيء بدء كتاب رسايل بريد الكترون تخطيط اجاز تشير تقدير شرك ابحاث اناليس شحن اجهز كمبيوتر شخص تعمل ذكاء اصطناع ستتجاوز مليو عام يشكل المء اجمال اجهز كمبيوتر مباع تكنولوج مستخدم اجهز كمبيوتر مزود ذكاء تات اجهز كمبيوتر شخص مزود ذكاء اصطناع معالج متخصص تسمى وحد معالج وال تتعامل غالب عمل متعلق ذكاء اصطناع جهاز تعمل وحد معالج عصب تناغم وحد معالج مركز معالج رسوم ادار مهام معقد تحس سرع معالج بيان تشغيل تطبيق مساعد افتراض يعمل ذكاء اصطناع انواع متوفر اجهز كمبيوتر مزود ذكاء اطلق مايكروسوف اثن اجهز وبايل ستبيع شرك مصنع ديل سامسونغ ينوف ايسر اسوس جيل جديد اجهز كمبيوتر لوح سيرفيس برو محمول سيرفيس ابتوب اطلق مايكروسوف اجهز وبايل اقل تبدء دولار جهاز جيل سادس جهاز ينوف ثين باد متوقع تبدء اسعار دولار خيار اغلى اسعار اعلن شرك مصنع اثار خاص رييس جديد مايكروسوف تسمى ريكول استدعاء مخاوف متعلق خصوص تتيح خاص رامج مساعد افتراض اجهز وبايل امكان بحث معلوم واسترداد نشاط سابق كمبيوتر تعمل خاص تتبع نشاط كمبيوتر محمول بدء محادث صوت حتى تصفح انشاء سجل مفصل مخز جهاز يمك مستخدم بحث سجل اطلاع انشط سابق مستخدم سايل تواصل اجتماع مخاوف ميز تساعد شبه ملياردير ايلو ماس مسلسل بلا ميرور انتاج نتفليكس يستعرض اثار ضار تكنولوج متقدم حسب رايا اولير محلل شرك انترناشونال دات مصدر قلق رييس خاص كان بيان مخزن جهاز مشير مخاطر كبير خصوص قام مايكروسوف تخز بيان ناح اخرى يقول خبراء ادار مزيد مهام متعلق ذكاء اصطناع مباشر جهاز توفر خصوص اكبر اظهر ابحاث اجر شرك ورستر اجهز كمبيوتر تعمل ذكاء اصطناع يمك تساعد تجنب استخدام بيان شخص تدريب انظم ذكاء تفاد انتهاك حقوق طبع نشر راء يجعل افضل استخدام موسس\n",
      "\n",
      "Preprocessed Text 2:\n",
      "اطلق مايكروسوف فء جديد اجهز كمبيوتر شخص مزود ميز ذكاء اصطناع الو تسارع دمج تكنولوج ناشء منتج عبر اعمال تنافس ابل الفاب وف موتمر مقر شرك ريدموند قدم رييس تنفيذ سات ناديل اسم مايكروسوف اجهز كمبيوتر شخص قايل انه ستبيع مجموع شرك ومن ايسر اسوس تيك مبيوتر اطلق مايكروسوف اجهز جديد تداول اسهم قرب مستو قياس ارتفاع وول ستر مدفوع توقع بان ذكاء اصطناع سيعزز ارباح شرك منافس شرك تكنولوج كبرى ويم لهذ اجهز تعامل مزيد مهام ذكاء اصطناع حاج مراكز بيان سيبدء سعر وشح ميز بحث فايق عرض مايكروسوف ميز تسمى ريكول وال ستساعد مستخدم عثور ملف يان اخرى شاهد اجهز كمبيوتر خاص كان علام تبويب مفتوح متصفح انتر كشف شرك مساعد صوت وبايل يعمل مدرب افتراض الو فعل مستخدم يمارس لعب فيديو ماينكراف قال يوسف يراس تسويق استهلاك لشرك شرك تتوقع شراء مليو جهاز مبيوتر شخص يعمل ذكاء اصطناع خلال عام مقبل تفيد يان لشرك ابحاث جارتنر بان شحن اجهز كمبيوتر شخص عالم انخفض بنح المء مليو جهاز عام يشير مايكروسوف تتوقع تمثل الفء جديد اجهز كمبيوتر اجمال اجهز كمبيوتر مباع قال مسوول تنفيذ مايكروسوف تشا احدث نسخ روبو دردش ذايع الص تشا طور شرك اوب ستكو متاح قريب كجزء مايكروسوف وبايل رنامج دردش الال تابع شرك اجهز لوح محمول طرح مايكروسوف جيل جديد اجهز كمبيوتر لوح سيرفيس برو محمول سيرفيس ابتوب تتميز شرايح والكوم كشف مايكروسوف تقن جديد يوم بدء موتمر سنو مطور كان اوب مدعوم جوجل تابع الفاب عرض اسبوع ماض تقن ذكاء اصطناع متنافس يمك استجاب عبر الص الو فعل ويم وكل السم مميز محادث صوت واقع استعص خدم مساعد صوت تعمل ذكاء اصطناع اعلن جوجل انه ستطرح عديد ميز ذكاء اصطناع توليد محر بحث مربح خاص تعرض صناع اجهز كمبيوتر ضغوط متزايد ابل اطلق شرك شرايح مستند تصميم شرك ارم تخلص معالج انتل منح معالج صمم ابل اجهز كمبيوتر شخص ماك عمر فايق بطار اداء اسرع شرايح منافس تستخدم مزيد طاق\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = SnowballStemmer('arabic')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('arabic'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Convert to lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "\n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in stemmed_tokens]\n",
    "\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Preprocess the texts\n",
    "preprocessed_texts = [preprocess_text(text) for text in texts]\n",
    "\n",
    "# Print the preprocessed texts\n",
    "for i, text in enumerate(preprocessed_texts):\n",
    "    print(f'Preprocessed Text {i+1}:\\n{text}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FxxW8hb4SorI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, scores):\n",
    "        self.texts = texts\n",
    "        self.scores = scores\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.scores[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q9uwhzi_Swbl"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class BiRNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BiRNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kLIQ-cLrS1lA"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for texts, scores in dataloader:\n",
    "            texts = texts.float()\n",
    "            scores = scores.float().view(-1, 1)\n",
    "\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, scores)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Bl4yLg2FS4Da"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for texts, scores in dataloader:\n",
    "            texts = texts.float()\n",
    "            scores = scores.float().view(-1, 1)\n",
    "\n",
    "            outputs = model(texts)\n",
    "            predictions.extend(outputs.numpy())\n",
    "            actuals.extend(scores.numpy())\n",
    "\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    return mse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNEGThaJS9LK",
    "outputId": "c07bea88-eb17-43a5-f131-b9f08ae42ef0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-cc670d295072>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  train_texts = torch.tensor(train_texts, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN model...\n",
      "Epoch [1/10], Loss: 35.9970\n",
      "Epoch [2/10], Loss: 29.8685\n",
      "Epoch [3/10], Loss: 24.4926\n",
      "Epoch [4/10], Loss: 19.8653\n",
      "Epoch [5/10], Loss: 15.9325\n",
      "Epoch [6/10], Loss: 12.6189\n",
      "Epoch [7/10], Loss: 9.8565\n",
      "Epoch [8/10], Loss: 7.5847\n",
      "Epoch [9/10], Loss: 5.7439\n",
      "Epoch [10/10], Loss: 4.2745\n",
      "RNN model Evaluation:\n",
      " - Mean Squared Error: 15.3657\n",
      " - Mean Absolute Error: 3.9199\n",
      "Training BiRNN model...\n",
      "Epoch [1/10], Loss: 35.3912\n",
      "Epoch [2/10], Loss: 28.8306\n",
      "Epoch [3/10], Loss: 23.0269\n",
      "Epoch [4/10], Loss: 17.9797\n",
      "Epoch [5/10], Loss: 13.6760\n",
      "Epoch [6/10], Loss: 10.0842\n",
      "Epoch [7/10], Loss: 7.1544\n",
      "Epoch [8/10], Loss: 4.8283\n",
      "Epoch [9/10], Loss: 3.0449\n",
      "Epoch [10/10], Loss: 1.7412\n",
      "BiRNN model Evaluation:\n",
      " - Mean Squared Error: 8.9982\n",
      " - Mean Absolute Error: 2.9997\n",
      "Training GRU model...\n",
      "Epoch [1/10], Loss: 33.4162\n",
      "Epoch [2/10], Loss: 28.5715\n",
      "Epoch [3/10], Loss: 24.1040\n",
      "Epoch [4/10], Loss: 19.9690\n",
      "Epoch [5/10], Loss: 16.1735\n",
      "Epoch [6/10], Loss: 12.7480\n",
      "Epoch [7/10], Loss: 9.7296\n",
      "Epoch [8/10], Loss: 7.1515\n",
      "Epoch [9/10], Loss: 5.0316\n",
      "Epoch [10/10], Loss: 3.3620\n",
      "GRU model Evaluation:\n",
      " - Mean Squared Error: 9.9709\n",
      " - Mean Absolute Error: 3.1577\n",
      "Training LSTM model...\n",
      "Epoch [1/10], Loss: 34.3875\n",
      "Epoch [2/10], Loss: 31.6788\n",
      "Epoch [3/10], Loss: 28.9480\n",
      "Epoch [4/10], Loss: 26.1077\n",
      "Epoch [5/10], Loss: 23.1268\n",
      "Epoch [6/10], Loss: 20.0370\n",
      "Epoch [7/10], Loss: 16.9342\n",
      "Epoch [8/10], Loss: 13.9576\n",
      "Epoch [9/10], Loss: 11.2401\n",
      "Epoch [10/10], Loss: 8.8680\n",
      "LSTM model Evaluation:\n",
      " - Mean Squared Error: 17.4159\n",
      " - Mean Absolute Error: 4.1732\n"
     ]
    }
   ],
   "source": [
    "preprocessed_texts = [np.random.rand(10, 100) for _ in range(2)]  # Example 2 texts, each with 10 words, 100-dim embeddings\n",
    "scores = [6, 7.5]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_texts, test_texts, train_scores, test_scores = train_test_split(preprocessed_texts, scores, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert lists to tensors\n",
    "train_texts = torch.tensor(train_texts, dtype=torch.float32)\n",
    "test_texts = torch.tensor(test_texts, dtype=torch.float32)\n",
    "train_scores = torch.tensor(train_scores, dtype=torch.float32)\n",
    "test_scores = torch.tensor(test_scores, dtype=torch.float32)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TextDataset(train_texts, train_scores)\n",
    "test_dataset = TextDataset(test_texts, test_scores)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 100  \n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'RNN': RNNModel(input_size, hidden_size, output_size),\n",
    "    'BiRNN': BiRNNModel(input_size, hidden_size, output_size),\n",
    "    'GRU': GRUModel(input_size, hidden_size, output_size),\n",
    "    'LSTM': LSTMModel(input_size, hidden_size, output_size)\n",
    "}\n",
    "\n",
    "# Training and evaluating each model\n",
    "for model_name, model in models.items():\n",
    "    print(f'Training {model_name} model...')\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_model(model, train_dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "    mse, mae = evaluate_model(model, test_dataloader)\n",
    "    print(f'{model_name} model Evaluation:')\n",
    "    print(f' - Mean Squared Error: {mse:.4f}')\n",
    "    print(f' - Mean Absolute Error: {mae:.4f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
